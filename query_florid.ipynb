{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9948473,"sourceType":"datasetVersion","datasetId":6117682}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"name":"notebook33c211fecb","provenance":[],"include_colab_link":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/sca-opdir/sentinel-data/blob/main/query_florid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n\n# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n\nimport kagglehub\n\nkagglehub.login()\n","metadata":{"id":"4vdsb0zLzyXs"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n\n# THEN FEEL FREE TO DELETE THIS CELL.\n\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n\n# NOTEBOOK.\n\n\n\nmzufferey_sentinel_path = kagglehub.dataset_download('mzufferey/sentinel')\n\n\n\nprint('Data source import complete.')\n","metadata":{"id":"36EDuRRszyXu"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nimport requests\n\nimport json\n\nimport os\n\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom queue import Queue\n\nimport threading\n\nimport csv\n\nfrom datetime import datetime\n\n\n\nnum_threads = os.cpu_count()\n\n\n\n# Chemin de sortie pour le fichier CSV\n\noutput_file = \"output_results_1000.csv\"\n\n\n\nkagout_file = '/kaggle/working/' + output_file\n\nif os.path.exists(kagout_file):\n\n    os.remove(kagout_file)\n\n\n\n\n\nprint(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:24:12.938148Z","iopub.execute_input":"2024-11-19T09:24:12.938543Z","iopub.status.idle":"2024-11-19T09:24:13.411484Z","shell.execute_reply.started":"2024-11-19T09:24:12.938507Z","shell.execute_reply":"2024-11-19T09:24:13.410381Z"},"id":"I2cLfZyWzyXu","outputId":"05f138ab-f435-4e10-e493-c22ac68d35b7"},"outputs":[{"name":"stdout","text":"2024-11-19 09:24:13 \n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"#central_points_url =\"https://github.com/sca-opdir/sentinel-data/raw/refs/heads/main/central_points_avecgeom.xlsx\"\n\ncentral_points_path = \"/kaggle/input/sentinel/central_points_avecgeom.xlsx\"\n\nliste_especes_path = \"/kaggle/input/sentinel/liste_espces.xlsx\"\n\n#liste_especes_url = \"https://github.com/sca-opdir/sentinel-data/raw/refs/heads/main/liste_esp%C3%A8ces.xlsx\"\n\n# df_central_points = pd.read_excel(central_points_url, engine=\"openpyxl\")\n\n# df_liste_especes = pd.read_excel(liste_especes_url)\n\ndf_central_points = pd.read_excel(central_points_path)\n\ndf_liste_especes = pd.read_excel(liste_especes_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:24:13.413685Z","iopub.execute_input":"2024-11-19T09:24:13.414171Z","iopub.status.idle":"2024-11-19T09:24:19.059137Z","shell.execute_reply.started":"2024-11-19T09:24:13.414135Z","shell.execute_reply":"2024-11-19T09:24:19.057997Z"},"id":"MhtEB3WbzyXv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fonction pour appeler l'API\n\ndef get_florID_resp(latcoord, loncoord, ntaxon, reqtaxons,\n\n                    reqdate=\"2024-06-20\", apiurl=\"https://speciesid.wsl.ch/florid\"):\n\n    url = apiurl\n\n    headers = {\n\n        \"accept\": \"*/*\",\n\n        \"Content-Type\": \"application/json\"\n\n    }\n\n    data = {\n\n        \"date\": reqdate,\n\n        \"lat\": latcoord,\n\n        \"lon\": loncoord,\n\n        \"num_taxon_ids\": ntaxon,\n\n        \"req_taxon_ids\": reqtaxons\n\n    }\n\n    response = requests.post(url, headers=headers, json=data)\n\n    if response.status_code == 200:\n\n        response_dict = response.json()\n\n        return {\n\n            \"center_x\": loncoord,\n\n            \"center_y\": latcoord,\n\n            \"req_taxa\": response_dict['requested_taxa']\n\n        }\n\n    else:\n\n        return None\n\n\n\n# Fonction pour traiter chaque point et envoyer les résultats à la file d’attente\n\ndef process_point(ipoint, output_queue):\n\n    ilat = df_central_points.center_y[ipoint]\n\n    ilon = df_central_points.center_x[ipoint]\n\n    ipoly = df_central_points.polygon_coords[ipoint]\n\n\n\n    api_resp = get_florID_resp(\n\n        latcoord=ilat,\n\n        loncoord=ilon,\n\n        ntaxon=5,\n\n        reqtaxons=list(df_liste_especes.taxon_id)\n\n    )\n\n\n\n    if api_resp:\n\n        row_data = {\n\n            \"center_x\": ilon,\n\n            \"center_y\": ilat,\n\n            \"polygon_coords\": ipoly\n\n        }\n\n        for idx, taxa_id in enumerate(api_resp['req_taxa']['id']):\n\n            taxa_nom = api_resp['req_taxa']['name'][idx]\n\n            ecological_model_value = api_resp['req_taxa']['ecological_model'][idx]\n\n            row_data[f\"{taxa_id} {taxa_nom}\"] = ecological_model_value\n\n\n\n        # Envoyer le résultat dans la file d’attente\n\n        output_queue.put(row_data)\n\n\n\n# Fonction pour écrire progressivement dans un fichier CSV\n\ndef writer(output_queue, output_file):\n\n    header_written = False\n\n    with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n\n        writer = None\n\n        while True:\n\n            row_data = output_queue.get()\n\n            if row_data is None:  # Indique la fin\n\n                break\n\n            if not header_written:\n\n                # Écrire l'en-tête\n\n                writer = csv.DictWriter(csvfile, fieldnames=row_data.keys())\n\n                writer.writeheader()\n\n                header_written = True\n\n            # Écrire une ligne\n\n            writer.writerow(row_data)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:24:19.060675Z","iopub.execute_input":"2024-11-19T09:24:19.061179Z","iopub.status.idle":"2024-11-19T09:24:19.072604Z","shell.execute_reply.started":"2024-11-19T09:24:19.061143Z","shell.execute_reply":"2024-11-19T09:24:19.071387Z"},"id":"hdETBfLIzyXv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# File d’attente pour les résultats\n\noutput_queue = Queue()\n\n\n\n\n\n# Lancer le thread consommateur pour écrire les résultats\n\nwriter_thread = threading.Thread(target=writer, args=(output_queue, output_file))\n\nwriter_thread.start()\n\n\n\n# Exécuter en parallèle les tâches de traitement\n\nwith ThreadPoolExecutor(max_workers=4) as executor:\n\n    #executor.map(lambda ipoint: process_point(ipoint, output_queue), range(df_central_points.shape[0]))\n\n    executor.map(lambda ipoint: process_point(ipoint, output_queue), range(1))\n\n\n\n# Indiquer la fin des écritures\n\noutput_queue.put(None)\n\n\n\n# Attendre la fin du thread consommateur\n\nwriter_thread.join()\n\n\n\nprint(\"Traitement terminé et fichier CSV créé.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:24:19.074063Z","iopub.execute_input":"2024-11-19T09:24:19.074428Z","iopub.status.idle":"2024-11-19T09:37:39.400165Z","shell.execute_reply.started":"2024-11-19T09:24:19.074397Z","shell.execute_reply":"2024-11-19T09:37:39.39903Z"},"id":"2G3ssMJZzyXw","outputId":"c1bdd19b-784b-424b-9123-07080e508e7e"},"outputs":[{"name":"stdout","text":"Traitement terminé et fichier CSV créé.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T09:37:57.03701Z","iopub.execute_input":"2024-11-19T09:37:57.037977Z","iopub.status.idle":"2024-11-19T09:37:57.044097Z","shell.execute_reply.started":"2024-11-19T09:37:57.037927Z","shell.execute_reply":"2024-11-19T09:37:57.042768Z"},"id":"tDBaJC6szyXw","outputId":"5987f346-49d2-4930-ab71-fd6d6d41b37e"},"outputs":[{"name":"stdout","text":"2024-11-19 09:37:57 \n\n","output_type":"stream"}],"execution_count":null}]}